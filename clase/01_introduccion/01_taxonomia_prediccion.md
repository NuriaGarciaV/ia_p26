# Taxonom√≠a de la Predicci√≥n en IA

Una gu√≠a completa para entender c√≥mo se aproxima el problema de predicci√≥n desde diferentes perspectivas.

---

## Parte 0: El Problema Fundamental

### ¬øQu√© es predecir?

En su forma m√°s general, **predecir** es estimar alguna cantidad desconocida a partir de informaci√≥n disponible.

**Notaci√≥n**:
- **Y**: Variable objetivo (lo que queremos predecir)
- **X**: Variables observables / features
- **Z**: Informaci√≥n auxiliar observable / proxies
- **L**: Variable latente (no observada, inferida por el modelo)
- **C**: Cluster o categor√≠a discreta
- **Œ∏**: Par√°metros del modelo

### El objetivo matem√°tico

Dependiendo del contexto, podemos querer estimar diferentes cantidades. Cada una responde a una pregunta diferente:

**Nota importante sobre la notaci√≥n:**
En estas notas usamos **E[¬∑]** (valor esperado/media) como el estad√≠stico principal por ser el m√°s com√∫n en la pr√°ctica. Sin embargo, formalmente podr√≠amos querer estimar **cualquier funcional o estad√≠stico** de la distribuci√≥n:

| Estad√≠stico | Notaci√≥n | Cu√°ndo usarlo |
|-------------|----------|---------------|
| **Media** | E[Y\|X] | Predicci√≥n puntual, minimiza MSE |
| **Mediana** | Q‚ÇÄ.‚ÇÖ[Y\|X] | Robusto a outliers, minimiza MAE |
| **Quantiles** | QŒ±[Y\|X] | Riesgo (VaR), intervalos de predicci√≥n |
| **Varianza** | Var[Y\|X] | Incertidumbre, volatilidad |
| **Moda** | Mode[Y\|X] | Valor m√°s probable |

Donde dice **E[Y\|X]**, l√©ase como "un estad√≠stico de Y dado X" - la media es simplemente el caso m√°s frecuente.

| Objetivo | Notaci√≥n | Descripci√≥n |
|----------|----------|-------------|
| Distribuci√≥n marginal de Y | **P(Y)** | Distribuci√≥n de Y sin condicionar en nada |
| Media incondicional | **E[Y]** | Solo la media de Y (el baseline m√°s simple) |
| Distribuci√≥n condicional completa | **P(Y\|X,Z)** | Toda la forma de la distribuci√≥n de Y dado X y Z |
| Valor esperado condicional | **E[Y\|X,Z]** | Solo la media de Y dado X y Z |
| Distribuci√≥n de los datos | **P(X)** o **P(X,Z)** | La densidad de los inputs (sin objetivo) |
| Representaci√≥n | **œï(X) ‚Üí ‚Ñù·µà** | Un embedding o compresi√≥n de X |
| Efecto causal | **P(Y\|do(X))** | El resultado de *intervenir* en X |

#### Explicaci√≥n de cada objetivo:

**P(Y) - Distribuci√≥n marginal**
> "¬øC√≥mo se distribuye Y en general, sin saber nada m√°s?"

Es la distribuci√≥n de Y ignorando cualquier informaci√≥n de X o Z. Es el punto de partida: si no conoces ning√∫n feature, ¬øqu√© puedes decir de Y?

*Ejemplo*: Distribuci√≥n de retornos diarios del S&P 500. Sin saber nada del contexto (qu√© d√≠a es, qu√© pas√≥ en el mercado), ¬øcu√°l es la probabilidad de un retorno de +2%? La respuesta est√° en P(Y).

**E[Y] - Media incondicional (el baseline)**
> "¬øCu√°l es el promedio hist√≥rico de Y?"

Es el predictor m√°s simple posible cuando no tienes features. **Todo modelo m√°s complejo debe superar este baseline** para justificar su complejidad.

**Nota**: El "mejor" estad√≠stico incondicional depende de la funci√≥n de p√©rdida:
| Si minimizas... | El baseline √≥ptimo es... | Notaci√≥n |
|-----------------|-------------------------|----------|
| Error cuadr√°tico (MSE) | **Media** | E[Y] |
| Error absoluto (MAE) | **Mediana** | Q‚ÇÄ.‚ÇÖ[Y] |
| P√©rdida asim√©trica | **Quantil** correspondiente | QŒ±[Y] |

*Ejemplo*: "El precio promedio de una casa es $300,000". Si tu modelo sofisticado con 50 features no supera esta predicci√≥n naive, algo est√° mal. E[Y] es el piso m√≠nimo de performance (para MSE).

**P(Y|X) - Distribuci√≥n condicional completa**
> "Dado que observo X, ¬øcu√°l es la distribuci√≥n completa de posibles valores de Y?"

No solo te dice el valor m√°s probable, sino toda la forma: ¬øes sim√©trica? ¬øtiene colas pesadas? ¬øes multimodal? Esto es crucial cuando necesitas cuantificar incertidumbre.

*Ejemplo*: Pron√≥stico del clima. No solo "ma√±ana habr√° 20¬∞C", sino la distribuci√≥n completa: 10% probabilidad de <15¬∞C, 60% de 18-22¬∞C, 30% de >22¬∞C.

**E[Y|X] - Valor esperado (media condicional)**
> "Dado que observo X, ¬øcu√°l es el valor promedio esperado de Y?"

Es un solo n√∫mero - el "mejor guess" en sentido de m√≠nimo error cuadr√°tico. Pierdes informaci√≥n sobre variabilidad.

*Ejemplo*: Predicci√≥n de precio de casa. El modelo dice "$250,000" - un n√∫mero, no una distribuci√≥n.

**Nota sobre series de tiempo:**
Las series de tiempo son un caso especial donde los features X son la **historia de la misma variable Y**:
- **P(Y_{t+1} | Y_t, Y_{t-1}, ...)** es P(Y|X) donde X = {Y_t, Y_{t-1}, ...}
- Modelos como AR, ARIMA, LSTM, y Transformers temporales usan esta estructura
- El baseline **E[Y]** sigue siendo relevante: un modelo temporal que no supere "predecir la media hist√≥rica" no aporta valor
- Tambi√©n existe el baseline "naive" de series de tiempo: predecir Y_{t+1} = Y_t (el √∫ltimo valor observado)

**La propiedad de Markov (memorylessness):**
Una simplificaci√≥n poderosa es asumir que **solo el presente importa**:
- **P(Y_{t+1} | Y_t, Y_{t-1}, ...) = P(Y_{t+1} | Y_t)** ‚Üê Propiedad de Markov
- "El futuro es independiente del pasado dado el presente"
- Reduce dr√°sticamente la complejidad: de historia infinita a un solo estado
- Es un supuesto **deductivo/h√≠brido**: decides a priori que la historia lejana es irrelevante
- Modelos: Cadenas de Markov, Hidden Markov Models (HMM), filtros de Kalman

**P(X) - Distribuci√≥n de los datos**
> "¬øCu√°l es la probabilidad de observar este input X?"

No hay variable objetivo Y. Modelas c√≥mo se distribuyen los datos en s√≠ mismos.

*Ejemplo*: Detecci√≥n de fraude. Si P(transacci√≥n) es muy baja, la transacci√≥n es "rara" ‚Üí posible fraude.

**œï(X) ‚Üí ‚Ñù·µà - Representaci√≥n (embedding)**
> "¬øC√≥mo puedo comprimir X en un vector de dimensi√≥n menor que capture su esencia?"

Es una funci√≥n determinista que mapea inputs a un espacio de menor dimensi√≥n. No es probabil√≠stico.

*Ejemplo*: Word2Vec convierte palabras en vectores de 300 dimensiones donde "rey - hombre + mujer ‚âà reina".

**P(Y|do(X)) - Efecto causal (intervenci√≥n)**
> "Si yo CAMBIO X activamente, ¬øqu√© pasa con Y?"

Es diferente de P(Y|X) que solo pregunta "si OBSERVO X". La diferencia es crucial:
- P(Y|X): "Las personas que toman aspirina tienen menos infartos" (correlaci√≥n)
- P(Y|do(X)): "Si le DOY aspirina a alguien, ¬øtendr√° menos infartos?" (causaci√≥n)

*Ejemplo*: Si observas que ciudades con m√°s helader√≠as tienen m√°s crimen, P(crimen|helader√≠as) es alto. Pero P(crimen|do(cerrar helader√≠as)) no baja el crimen - ambos son causados por el calor.

### Jerarqu√≠a de generalidad

```
                                    M√°s informaci√≥n / M√°s general
                                              ‚ñ≤
                                              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                                           ‚îÇ
‚îÇ   P(X,Y,Z)  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Distribuci√≥n conjunta completa                        ‚îÇ
‚îÇ       ‚îÇ                                                                                   ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚ñ∫ P(Y|X,Z) ‚îÄ‚îÄ‚ñ∫ E[Y|X,Z] ‚îÄ‚îÄ‚ñ∫ Predicci√≥n condicional                               ‚îÇ
‚îÇ       ‚îÇ        ‚îÇ                                                                          ‚îÇ
‚îÇ       ‚îÇ        ‚îî‚îÄ‚îÄ‚ñ∫ Var[Y|X,Z], Q_Œ±[Y|X,Z] ‚îÄ‚îÄ‚ñ∫ Varianza, quantiles                        ‚îÇ
‚îÇ       ‚îÇ                                                                                   ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚ñ∫ P(Y) ‚îÄ‚îÄ‚ñ∫ E[Y] ‚îÄ‚îÄ‚ñ∫ Baseline (predicci√≥n sin features)                           ‚îÇ
‚îÇ       ‚îÇ                                                                                   ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚ñ∫ P(X,Z) ‚îÄ‚îÄ‚ñ∫ P(X) ‚îÄ‚îÄ‚ñ∫ Generaci√≥n, detecci√≥n de anomal√≠as                         ‚îÇ
‚îÇ       ‚îÇ                 ‚îÇ                                                                 ‚îÇ
‚îÇ       ‚îÇ                 ‚îî‚îÄ‚îÄ‚ñ∫ œï(X) ‚îÄ‚îÄ‚ñ∫ Representaci√≥n (compresi√≥n con p√©rdida)             ‚îÇ
‚îÇ       ‚îÇ                                                                                   ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚ñ∫ P(X|Y) ‚îÄ‚îÄ‚ñ∫ Inferencia inversa (¬øqu√© X gener√≥ este Y?)                          ‚îÇ
‚îÇ                                                                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ
                                              ‚ñº
                                    Menos informaci√≥n / M√°s espec√≠fico


    ¬øY el efecto causal P(Y|do(X))?
    
    P(Y|do(X)) NO se deriva de P(X,Y) directamente. Requiere informaci√≥n adicional:
    estructura causal (un DAG) que te dice qu√© variables causan qu√©.
    
    P(X,Y,Z) + Estructura Causal ‚îÄ‚îÄ‚ñ∫ P(Y|do(X))
```

**Regla clave**: Si conoces una cantidad m√°s general (arriba), puedes derivar las m√°s espec√≠ficas (abajo). No al rev√©s.

**¬øPor qu√© œï(X) est√° "debajo" de P(X)?**
- De P(X) puedes derivar muchas representaciones œï(X) (ej: los modos de la distribuci√≥n, componentes principales)
- De œï(X) no puedes recuperar P(X) - perdiste informaci√≥n al comprimir

**¬øPor qu√© P(Y|do(X)) est√° separado?**
- No puedes derivar efectos causales solo de datos observacionales P(X,Y)
- Necesitas supuestos adicionales sobre la estructura causal
- Por eso causalidad requiere m√°s que solo "m√°s datos"

**¬øPor qu√© E[Y] importa como baseline?**

E[Y] es el **baseline universal** contra el que todo modelo predictivo debe compararse:
- Si tu modelo E[Y|X] no mejora sobre predecir E[Y] siempre, los features X no aportan informaci√≥n √∫til
- En ML esto se mide con m√©tricas como **R¬≤** (qu√© porcentaje de varianza explica el modelo sobre el baseline)
- Un R¬≤ de 0 significa: "mi modelo sofisticado no es mejor que predecir la media"
- Un R¬≤ negativo significa: "mi modelo es PEOR que predecir la media" (sobreajuste o error)

La pregunta fundamental antes de construir cualquier modelo complejo es: **¬øMis features X realmente ayudan a predecir Y mejor que simplemente usar E[Y]?**

Por ejemplo:
- De **P(Y|X)** puedes calcular **E[Y|X] = ‚à´ y ¬∑ P(y|X) dy**
- De **E[Y|X]** **no puedes** recuperar **P(Y|X)** (perdiste informaci√≥n sobre varianza, forma, etc.)

### El problema fundamental: Restricci√≥n

**El dilema**:
- Tenemos **datos finitos** (N observaciones)
- El espacio de funciones posibles es **infinito**
- Hay infinitos modelos que ajustan perfectamente los datos de entrenamiento

**Consecuencia**: 
Todo m√©todo de predicci√≥n es una forma de **restringir el espacio de hip√≥tesis**. Las diferencias entre m√©todos son diferencias en:
1. **Qu√© restricciones** imponen
2. **De d√≥nde vienen** esas restricciones
3. **C√≥mo se expresan** matem√°ticamente

Esta es la base de nuestra taxonom√≠a.

---

## Parte 1: Las 5 Dimensiones Ortogonales

No existe UNA forma correcta de categorizar los m√©todos de predicci√≥n. Existen **5 ejes independientes** que caracterizan cualquier approach. Cada m√©todo es un punto en este espacio 5-dimensional.

```
M√©todo = (D1: Fuente de Estructura, 
          D2: Interpretaci√≥n de Probabilidad, 
          D3: Objetivo Matem√°tico, 
          D4: Arquitectura de Variables, 
          D5: Mecanismo de Restricci√≥n)
```

Las dimensiones son **ortogonales**: puedes elegir cualquier combinaci√≥n de opciones en cada eje.

---

### Dimensi√≥n 1: Fuente del Conocimiento Estructural

**Pregunta clave**: *"¬øDe d√≥nde viene la estructura del modelo?"*

Esta es quiz√°s la dimensi√≥n m√°s fundamental. Antes de hablar de algoritmos o matem√°ticas, debemos preguntarnos: ¬øqu√© **sabemos** (o creemos saber) sobre el problema antes de ver los datos?

| Tipo | Descripci√≥n | Ejemplos | Situaci√≥n real |
|------|-------------|----------|----------------|
| **Deductivo** | La estructura viene de teor√≠a/axiomas previos a los datos | Modelos f√≠sicos, DSGE en econom√≠a, sistemas expertos | *Simulaci√≥n de vuelo*: ecuaciones de aerodin√°mica definen el modelo, datos solo validan |
| **Inductivo** | La estructura emerge de patrones en los datos | ML cl√°sico, Deep Learning, clustering | *Recomendador de Netflix*: no hay "teor√≠a de gustos", solo patrones en millones de usuarios |
| **H√≠brido** | Teor√≠a provee esqueleto, datos ajustan par√°metros | Calibraci√≥n econ√≥mica, Physics-Informed NNs, Bayesian con priors informativos | *Modelo macroecon√≥mico*: teor√≠a dice que consumo depende de ingreso esperado, datos calibran elasticidades |

---

#### Enfoque Deductivo: "La teor√≠a primero"

En el enfoque deductivo, **la estructura del modelo existe antes de ver cualquier dato**. Viene de:
- Leyes f√≠sicas (Newton, Maxwell, termodin√°mica)
- Axiomas econ√≥micos (optimizaci√≥n de agentes, equilibrio de mercados)
- L√≥gica formal (reglas de inferencia, ontolog√≠as)

**Flujo deductivo:**
```
Axiomas/Teor√≠a  ‚îÄ‚îÄ‚ñ∫  Modelo Matem√°tico  ‚îÄ‚îÄ‚ñ∫  Predicciones  ‚îÄ‚îÄ‚ñ∫  Datos validan/refutan
```

**Caracter√≠sticas:**
- El modelo puede existir sin datos (ej: ecuaciones de Einstein exist√≠an antes de confirmarlas)
- Los datos sirven para **validar** o **refutar**, no para descubrir estructura
- Alta interpretabilidad: cada t√©rmino tiene significado te√≥rico
- Puede fallar si la teor√≠a est√° equivocada

**Ejemplo detallado - F√≠sica:**
Las ecuaciones de Navier-Stokes describen fluidos. No las "aprendimos" de datos - las derivamos de principios de conservaci√≥n (masa, momento, energ√≠a). Un simulador de clima usa estas ecuaciones; los datos solo calibran condiciones iniciales.

**Ejemplo detallado - Econom√≠a (DSGE):**
Un modelo DSGE parte de supuestos: hogares maximizan utilidad, firmas maximizan ganancias, mercados se equilibran. De estos axiomas se derivan ecuaciones (Euler, Phillips). La estructura est√° fijada; los datos solo determinan valores de par√°metros como elasticidades.

---

#### Enfoque Inductivo: "Los datos primero"

En el enfoque inductivo, **la estructura emerge de los patrones en los datos**. No hay teor√≠a previa que dicte la forma funcional.

**Flujo inductivo:**
```
Datos  ‚îÄ‚îÄ‚ñ∫  Buscar patrones  ‚îÄ‚îÄ‚ñ∫  Modelo que ajusta  ‚îÄ‚îÄ‚ñ∫  Predicciones
```

**Caracter√≠sticas:**
- Sin datos, no hay modelo
- El modelo "descubre" relaciones que no conoc√≠amos
- Puede encontrar patrones no lineales, interacciones complejas
- Riesgo: puede encontrar patrones espurios (correlaci√≥n sin causaci√≥n)
- Menor interpretabilidad: ¬øqu√© significa el peso 0.73 en la capa 5?

**Ejemplo detallado - Recomendador de Netflix:**
No existe una "teor√≠a de gustos cinematogr√°ficos" que diga que si te gusta X, te gustar√° Y. El sistema observa millones de usuarios, encuentra patrones (gente que vio A tambi√©n vio B), y los explota. La estructura (qu√© factores importan) emerge de los datos.

**Ejemplo detallado - Reconocimiento de im√°genes:**
No hay axiomas que digan "un gato tiene orejas puntiagudas y bigotes". La red neuronal ve millones de im√°genes etiquetadas y aprende features discriminativas. Nadie program√≥ qu√© buscar.

---

#### Enfoque H√≠brido: "Lo mejor de ambos mundos"

El enfoque h√≠brido combina conocimiento te√≥rico con aprendizaje de datos. La teor√≠a provee el **esqueleto**, los datos ajustan los **detalles**.

**Flujo h√≠brido:**
```
Teor√≠a parcial  ‚îÄ‚îÄ‚ñ∫  Estructura con "huecos"  ‚îÄ‚îÄ‚ñ∫  Datos llenan huecos  ‚îÄ‚îÄ‚ñ∫  Modelo completo
```

**Variantes del enfoque h√≠brido:**

| Variante | Qu√© provee la teor√≠a | Qu√© proveen los datos |
|----------|---------------------|----------------------|
| **Calibraci√≥n** | Forma funcional completa | Valores de par√°metros |
| **Physics-Informed NN** | Restricciones (ej: conservaci√≥n de energ√≠a) | Funci√≥n de aproximaci√≥n |
| **Priors informativos** | Distribuci√≥n a priori sobre par√°metros | Actualizaci√≥n posterior |
| **Modelos semi-param√©tricos** | Parte param√©trica (teor√≠a) | Parte no-param√©trica (datos) |

**Ejemplo detallado - Calibraci√≥n econ√≥mica:**
Un modelo macroecon√≥mico tiene la forma: `C = f(Y, r, Œ∏)` donde:
- La teor√≠a dice que Consumo (C) depende de Ingreso (Y) y tasa de inter√©s (r)
- La forma funcional f viene de optimizaci√≥n de hogares
- Pero el par√°metro Œ∏ (elasticidad) no lo dice la teor√≠a
- Los datos determinan Œ∏ mediante match de momentos (ej: ajustar para que el modelo reproduzca la volatilidad observada del PIB)

**Ejemplo detallado - Physics-Informed Neural Networks:**
Quieres predecir el flujo de calor en un material. Sabes que debe satisfacer la ecuaci√≥n de calor (‚àÇT/‚àÇt = Œ±‚àá¬≤T). En lugar de solo minimizar error de predicci√≥n, agregas un t√©rmino al loss que penaliza violar la ecuaci√≥n. La red aprende una funci√≥n que:
1. Ajusta los datos observados
2. Respeta la f√≠sica conocida

---

**El caso de la calibraci√≥n econ√≥mica (expandido):** 

La calibraci√≥n es el ejemplo can√≥nico de enfoque h√≠brido en ciencias sociales:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                     ‚îÇ
‚îÇ   TEOR√çA (Deductivo)                    DATOS (Inductivo)          ‚îÇ
‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                     ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ           ‚îÇ
‚îÇ   ‚Ä¢ Hogares maximizan utilidad          ‚Ä¢ Series de tiempo del PIB ‚îÇ
‚îÇ   ‚Ä¢ Firmas maximizan ganancias          ‚Ä¢ Inflaci√≥n observada      ‚îÇ
‚îÇ   ‚Ä¢ Mercados se equilibran              ‚Ä¢ Tasas de inter√©s         ‚îÇ
‚îÇ            ‚îÇ                                     ‚îÇ                  ‚îÇ
‚îÇ            ‚ñº                                     ‚ñº                  ‚îÇ
‚îÇ   Ecuaciones estructurales              Momentos emp√≠ricos         ‚îÇ
‚îÇ   (Euler, Phillips, etc.)               (media, varianza, corr)    ‚îÇ
‚îÇ            ‚îÇ                                     ‚îÇ                  ‚îÇ
‚îÇ            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ
‚îÇ                           ‚ñº                                         ‚îÇ
‚îÇ                    CALIBRACI√ìN                                      ‚îÇ
‚îÇ            Encontrar Œ∏ tal que momentos del                         ‚îÇ
‚îÇ            modelo ‚âà momentos de los datos                           ‚îÇ
‚îÇ                           ‚îÇ                                         ‚îÇ
‚îÇ                           ‚ñº                                         ‚îÇ
‚îÇ                  Modelo calibrado                                   ‚îÇ
‚îÇ            (estructura te√≥rica + par√°metros emp√≠ricos)              ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

La teor√≠a te dice *qu√©* variables se relacionan y *c√≥mo* (funcionalmente). Los datos te dicen los *valores num√©ricos* de los par√°metros.

**Nota importante: DSGE vs Calibraci√≥n**

Es com√∫n confundir estos t√©rminos porque suelen aparecer juntos, pero son cosas distintas:

| Concepto | ¬øQu√© es? | Dimensi√≥n |
|----------|----------|-----------|
| **DSGE** | Un **tipo de modelo** (estructura basada en teor√≠a micro: agentes optimizando, equilibrio general) | D1 (Deductivo) + D4 (Arquitectura de grafo/ecuaciones) |
| **Calibraci√≥n** | Una **t√©cnica de estimaci√≥n** (elegir par√°metros para reproducir momentos observados) | D5 (Mecanismo de restricci√≥n) |

```
DSGE puede estimarse con:        Calibraci√≥n puede aplicarse a:
‚îú‚îÄ‚îÄ Calibraci√≥n ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îú‚îÄ‚îÄ DSGE
‚îú‚îÄ‚îÄ Maximum Likelihood           ‚îú‚îÄ‚îÄ Modelos de agentes
‚îú‚îÄ‚îÄ Bayesiano                    ‚îú‚îÄ‚îÄ Simulaciones f√≠sicas
‚îî‚îÄ‚îÄ GMM (Momentos Generalizados) ‚îî‚îÄ‚îÄ Cualquier modelo con par√°metros libres
```

En otras palabras: **DSGE es el "qu√©"** (qu√© modelo usas), **calibraci√≥n es el "c√≥mo"** (c√≥mo estimas sus par√°metros).

---

**Intuici√≥n resumida:**
- **Deductivo**: "S√© c√≥mo funciona el mundo; los datos confirman"
- **Inductivo**: "No s√© c√≥mo funciona; los datos me lo dir√°n"
- **H√≠brido**: "Tengo una idea aproximada; los datos la refinan"

**¬øCu√°ndo usar cada uno?**

| Situaci√≥n | Enfoque recomendado |
|-----------|---------------------|
| Tienes teor√≠a s√≥lida y bien establecida | Deductivo |
| No hay teor√≠a, solo datos abundantes | Inductivo |
| Teor√≠a parcial + necesitas generalizar | H√≠brido |
| Datos escasos pero conocimiento experto | H√≠brido (priors) |
| Necesitas interpretabilidad/explicabilidad | Deductivo o H√≠brido |
| Solo importa precisi√≥n predictiva | Inductivo |

---

### Dimensi√≥n 2: Interpretaci√≥n de Probabilidad/Incertidumbre

**Pregunta clave**: *"Cuando digo 'hay 70% de probabilidad de lluvia', ¬øqu√© significa ese n√∫mero?"*

| Interpretaci√≥n | Filosof√≠a | Qu√© es un par√°metro **Œ∏** | Qu√© es incertidumbre | Situaci√≥n real |
|----------------|-----------|------------------------------|----------------------|----------------|
| **Frequentist** | Probabilidad = frecuencia l√≠mite en repeticiones infinitas | Constante fija desconocida | Variabilidad muestral | *A/B testing*: "si repitiera el experimento infinitas veces, ¬øqu√© fracci√≥n favorece A?" |
| **Bayesian** | Probabilidad = grado de creencia subjetivo | Variable aleatoria con distribuci√≥n | Se actualiza con evidencia | *Diagn√≥stico m√©dico*: "dado el historial del paciente, mi creencia de que tiene X es 30%" |
| **Propensity** | Probabilidad = tendencia inherente del sistema | Propiedad del mecanismo causal | Irreducible, parte de la realidad | *F√≠sica cu√°ntica*: la probabilidad es propiedad del electr√≥n, no de nuestra ignorancia |

---

#### Nota filos√≥fica: Tipos de incertidumbre y el debate Popper-Jaynes

La distinci√≥n entre interpretaciones tiene ra√≠ces filos√≥ficas profundas sobre la **naturaleza de la incertidumbre**:

**Karl Popper y la Propensity:**
Popper argument√≥ que la probabilidad puede ser una **tendencia objetiva** del mundo f√≠sico - una "propensi√≥n" real del sistema a producir ciertos resultados. Bajo esta vista, cuando decimos que un electr√≥n tiene 50% de probabilidad de spin-up, esto es una propiedad f√≠sica del electr√≥n, no de nuestro conocimiento.

**E.T. Jaynes y la incertidumbre epist√©mica:**
En *"Probability Theory: The Logic of Science"*, Jaynes argumenta algo diferente. Considera el ejemplo de una **urna con bolas** o una **baraja de cartas**:

> Cuando asignamos P = 1/52 a sacar el As de Espadas de una baraja "bien barajada", ¬øes porque la baraja tiene una "propensi√≥n" objetiva? 

Jaynes dir√≠a: **No**. La baraja tiene un orden f√≠sico determinado despu√©s de barajar. Si conoci√©ramos exactamente:
- La posici√≥n inicial de cada carta
- La mec√°nica exacta de cada movimiento del barajeo
- Las propiedades f√≠sicas de las cartas

...podr√≠amos predecir el orden final con certeza. La probabilidad 1/52 refleja **nuestra ignorancia** (o nuestra decisi√≥n de no modelar la f√≠sica), no una propiedad de la baraja.

**Dos tipos de incertidumbre:**

| Tipo | Nombre | Descripci√≥n | ¬øReducible? | Ejemplo |
|------|--------|-------------|-------------|---------|
| **Epist√©mica** | "No s√©" | Incertidumbre por falta de conocimiento | S√≠, con m√°s informaci√≥n | Baraja: no conozco el orden, pero existe uno |
| **Aleatoria** | "No se puede saber" | Incertidumbre irreducible del sistema | No, es fundamental | ¬øMec√°nica cu√°ntica? (debatido) |

**La posici√≥n de Jaynes:**
Para Jaynes, casi toda la "aleatoriedad" que usamos en estad√≠stica y ML es realmente **epist√©mica disfrazada**. Modelamos urnas, dados, y barajas como "aleatorios" porque:
1. No conocemos los detalles mec√°nicos
2. No queremos (o no podemos) modelarlos
3. La aproximaci√≥n probabil√≠stica funciona bien en la pr√°ctica

Esto no significa que la probabilidad sea in√∫til - al contrario, Jaynes la defiende como **la herramienta correcta para razonar bajo incertidumbre**. Pero es honesto sobre su naturaleza: describe nuestro estado de conocimiento, no necesariamente el mundo.

**Implicaci√≥n pr√°ctica:**
En ML, la distinci√≥n aparece como:
- **Incertidumbre epist√©mica** ‚Üí Incertidumbre sobre los par√°metros del modelo (reducible con m√°s datos)
- **Incertidumbre aleatoria (aleatoric)** ‚Üí "Ruido" en los datos (supuestamente irreducible)

Pero siguiendo a Jaynes, incluso lo que llamamos "ruido aleatorio" puede ser epist√©mico - variables que no medimos o no incluimos en el modelo.

---

**Implicaciones pr√°cticas**:

| Aspecto | Frequentist | Bayesian |
|---------|-------------|----------|
| Output del modelo | Punto √≥ptimo **Œ∏ÃÇ** | Distribuci√≥n **P(Œ∏\|Data)** |
| Intervalos de confianza | "Si repitiera, 95% contendr√≠an el verdadero valor" | "Hay 95% de probabilidad de que **Œ∏** est√© aqu√≠" |
| Priors | No existen (o son impl√≠citos) | Expl√≠citos y requeridos |
| Computaci√≥n | T√≠picamente m√°s simple | T√≠picamente m√°s costosa (MCMC, VI) |

**Nota importante**: Puedes ser Deductivo+Frequentist, Deductivo+Bayesian, Inductivo+Frequentist, Inductivo+Bayesian. Son ejes independientes.

---

### Dimensi√≥n 3: Objetivo Matem√°tico

**Pregunta clave**: *"¬øQu√© cantidad est√°s tratando de estimar?"*

**Nota sobre notaci√≥n de variables:**
| S√≠mbolo | Significado | Ejemplo |
|---------|-------------|---------|
| **X** | Features/inputs observados | Imagen, texto, mediciones |
| **Y** | Variable objetivo a predecir | Etiqueta, precio, categor√≠a |
| **Z** | Variable auxiliar observada (informaci√≥n extra) | Metadata, contexto, otra modalidad |
| **L** | Variable latente (no observada, inferida) | Representaci√≥n comprimida, estado oculto |
| **C** | Cluster o categor√≠a discreta | Segmento de cliente, t√≥pico |

La diferencia clave: **Z es observable** (la tienes en tus datos), **L es latente** (la infiere el modelo).

#### Caso A: CON variable objetivo Y (Supervised)

| Objetivo | Notaci√≥n | Qu√© obtienes | Cu√°ndo usarlo | Situaci√≥n real |
|----------|----------|--------------|---------------|----------------|
| **Distribuci√≥n condicional** | **P(Y\|X)** | Forma completa de la distribuci√≥n | Necesitas incertidumbre completa | *Pron√≥stico meteorol√≥gico*: no solo "llover√°" sino probabilidad por intensidad |
| **Valor esperado** | **E[Y\|X]** | Solo la media | Predicci√≥n puntual suficiente | *Precio de casa*: quieres UN n√∫mero |
| **Efecto causal** | **P(Y\|do(X))** | Resultado de intervenci√≥n | Decisiones, pol√≠ticas | *Pricing*: ¬øqu√© pasa si CAMBIO el precio del producto? |
| **Quantiles/Intervalos** | **QŒ±(Y\|X)** | Percentiles espec√≠ficos | Riesgo, predicci√≥n robusta | *VaR en finanzas*: ¬øcu√°l es la p√©rdida m√°xima al 95%? |

#### Caso B: SIN variable objetivo (Unsupervised)

| Objetivo | Notaci√≥n | Qu√© obtienes | Cu√°ndo usarlo | Situaci√≥n real |
|----------|----------|--------------|---------------|----------------|
| **Distribuci√≥n de datos** | **P(X)** | Densidad de probabilidad | Detecci√≥n de anomal√≠as, generaci√≥n | *Fraude*: transacciones con baja **P(X)** son sospechosas |
| **Representaci√≥n** | **œï(X) ‚Üí L** | Embedding/compresi√≥n (L es latente) | Reducci√≥n de dimensi√≥n, transfer | *Autoencoder*: comprimir im√°genes; *BERT*: embeddings de texto |
| **Estructura latente discreta** | **P(C\|X)** | Asignaci√≥n a clusters | Segmentaci√≥n, taxonom√≠a | *Segmentar clientes* en grupos de comportamiento |
| **Reconstrucci√≥n** | **E[X]** o **XÃÇ** | Versi√≥n "limpia" de input | Denoising, imputaci√≥n | *Restaurar imagen borrosa*, completar datos faltantes |

#### Caso C: MIXTO (Self-supervised, Generativo)

| Objetivo | Notaci√≥n | Qu√© obtienes | Cu√°ndo usarlo | Situaci√≥n real |
|----------|----------|--------------|---------------|----------------|
| **Distribuci√≥n con latentes** | **P(X,L)** | Modelo generativo con espacio latente | Datos faltantes, generaci√≥n | *VAE*: generar caras nuevas; L captura variaciones |
| **Predicci√≥n de parte de X** | **P(X‚ÇÇ\|X‚ÇÅ)** | Y derivado del mismo X | Pretraining, representaciones | *GPT*: predecir siguiente palabra; *BERT*: predecir palabra enmascarada |

---

### Dimensi√≥n 4: Arquitectura de Variables

**Pregunta clave**: *"¬øLas variables solo se usan como inputs, o tienen una relaci√≥n estructural espec√≠fica entre ellas?"*

**Terminolog√≠a de grafos:**
| T√©rmino | Significado | Visualizaci√≥n |
|---------|-------------|---------------|
| **DAG** | Directed Acyclic Graph (grafo dirigido sin ciclos) | A ‚Üí B ‚Üí C (flechas, no puedes volver al inicio) |
| **MRF** | Markov Random Field (grafo no dirigido) | A ‚Äî B ‚Äî C (conexiones sin direcci√≥n) |
| **PGM** | Probabilistic Graphical Model (t√©rmino general) | Incluye DAGs (Bayesian Networks) y MRFs |

```
DAG (Bayesian Network):       MRF (Markov Random Field):
    A ‚îÄ‚îÄ‚îÄ‚ñ∫ B                      A ‚îÄ‚îÄ‚îÄ B
    ‚îÇ      ‚îÇ                      ‚îÇ     ‚îÇ
    ‚ñº      ‚ñº                      ‚îÇ     ‚îÇ
    C ‚îÄ‚îÄ‚îÄ‚ñ∫ D                      C ‚îÄ‚îÄ‚îÄ D

Flechas = direcci√≥n causal    L√≠neas = dependencia sim√©trica
```

| Arquitectura | Estructura | Supuesto impl√≠cito | Mejor para | Situaci√≥n real |
|--------------|------------|-------------------|------------|----------------|
| **Flat/Discriminativa** | **[X, Z] ‚Üí Y** | Variables son intercambiables como inputs | Alta precisi√≥n con muchos datos | *Clasificaci√≥n de spam*: todas las features son inputs equivalentes |
| **Generativa** | Modelo de **P(X,Z)** junto con Y | El mundo tiene estructura que podemos simular | Datos faltantes, generaci√≥n | *Generar rostros*: necesitas entender c√≥mo se distribuyen los pixels |
| **Latente** | X,Z son vistas ruidosas de **L** oculto | La realidad es m√°s simple que las observaciones | Ruido, fusi√≥n de sensores | *GPS + aceler√≥metro*: ambos miden posici√≥n real con ruido diferente |
| **Grafos/PGM** | DAG o MRF de dependencias | Independencias condicionales expl√≠citas | Interpretabilidad, conocimiento experto | *Diagn√≥stico m√©dico*: s√≠ntomas dependen de enfermedad, no entre s√≠ |
| **Causal** | DAG con direcci√≥n causal | Mecanismos son estables bajo intervenci√≥n | Decisiones, robustez OOD | *Pol√≠tica p√∫blica*: ¬øsubir impuestos CAUSA menos consumo? |

**Discriminativo vs Generativo - La distinci√≥n clave:**

| Enfoque | Qu√© modela | Pregunta que responde | ¬øPuede generar datos nuevos? |
|---------|------------|----------------------|------------------------------|
| **Discriminativo** | **P(Y\|X)** | "Dado este input X, ¬øcu√°l es Y?" | No directamente |
| **Generativo** | **P(X)** o **P(X,Y)** | "¬øC√≥mo se ven los datos?" | S√≠, muestreando de P(X) |

*Ejemplo - Clasificar gatos vs perros:*
- **Discriminativo** (ej: Logistic Regression, SVM): Aprende la frontera de decisi√≥n entre gatos y perros. No sabe "c√≥mo se ve un gato", solo sabe distinguirlos.
- **Generativo** (ej: Naive Bayes, Gaussian Mixture): Aprende P(X|gato) y P(X|perro) - c√≥mo se ven los gatos, c√≥mo se ven los perros. Puede generar im√°genes nuevas Y clasificar usando Bayes.

```
DISCRIMINATIVO:     X ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ P(Y|X) ‚îÄ‚îÄ‚ñ∫ ≈∂
                    (aprende frontera directamente)

GENERATIVO:         Aprende P(X|Y) para cada Y
                              ‚îÇ
                              ‚ñº
                    Clasifica via Bayes: P(Y|X) ‚àù P(X|Y)P(Y)
                    Genera muestreando de P(X|Y)
```

**Aclaraci√≥n importante - Dos significados de "Generativo":**

El t√©rmino "generativo" se usa en ML con dos significados que a veces se confunden:

| Significado | Definici√≥n | Ejemplo |
|-------------|------------|---------|
| **Arquitectura generativa** (cl√°sico) | Modelar P(X) o P(X,Y) en lugar de solo P(Y\|X) | Naive Bayes, Gaussian Mixture, VAE |
| **IA Generativa** (moderno) | Cualquier modelo capaz de **generar contenido nuevo** | GPT, Stable Diffusion, DALL-E |

*¬øPor qu√© la confusi√≥n?* Un LLM como GPT modela **P(X‚Çú‚Çä‚ÇÅ\|X‚ÇÅ:‚Çú)**, que t√©cnicamente es condicional (discriminativo en cierto sentido). Pero al encadenar estas predicciones, genera secuencias completas de texto - por eso lo llamamos "generativo" en el sentido de capacidad.

```
GPT:  P(X‚ÇÇ|X‚ÇÅ) √ó P(X‚ÇÉ|X‚ÇÅ,X‚ÇÇ) √ó P(X‚ÇÑ|X‚ÇÅ,X‚ÇÇ,X‚ÇÉ) √ó ... = P(X‚ÇÅ,X‚ÇÇ,X‚ÇÉ,X‚ÇÑ,...)
      ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      Predicciones condicionales encadenadas = Distribuci√≥n conjunta P(X)
```

**En resumen**: GPT es generativo en **capacidad** (genera texto) aunque su objetivo inmediato sea condicional.

**Visualizaci√≥n de arquitecturas**:

*Nota: **Œ∏** (theta) representa los **par√°metros del modelo** - los n√∫meros que se aprenden/ajustan durante el entrenamiento (pesos, coeficientes, etc.)*

```
FLAT:           X‚ÇÅ, X‚ÇÇ, Z‚ÇÅ, Z‚ÇÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫  f(¬∑;Œ∏)  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫  Y
                                          (Œ∏ = par√°metros de f)

GENERATIVA (con etiquetas, ej: Naive Bayes):
                
                Œ∏ ‚îÄ‚îÄ‚îÄ‚ñ∫ P(X|Y;Œ∏) ‚îÄ‚îÄ‚îÄ‚ñ∫ Para clasificar: P(Y|X) ‚àù P(X|Y)P(Y)
                                 ‚îî‚îÄ‚îÄ‚ñ∫ Para generar: muestrear X ~ P(X|Y=clase)

GENERATIVA (sin etiquetas, ej: VAE, GAN):
                
                L ~ P(L)  ‚îÄ‚îÄ‚îÄ‚ñ∫  Decoder/Generator  ‚îÄ‚îÄ‚îÄ‚ñ∫  X generado
                (latente)       P(X|L;Œ∏)                 (imagen, texto, etc.)

LATENTE:        L (oculto)
                 ‚îú‚îÄ‚îÄ‚îÄ‚ñ∫  X (vista ruidosa 1)
                 ‚îú‚îÄ‚îÄ‚îÄ‚ñ∫  Z (vista ruidosa 2)
                 ‚îî‚îÄ‚îÄ‚îÄ‚ñ∫  Y

PGM (general):  A ‚îÄ‚îÄ‚îÄ‚ñ∫ B ‚îÄ‚îÄ‚îÄ‚ñ∫ C
                       ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚ñ∫ D

    Ejemplos espec√≠ficos de PGM:
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                                                                 ‚îÇ
    ‚îÇ  MARKOV:      X_t ‚îÄ‚îÄ‚îÄ‚ñ∫ X_{t+1} ‚îÄ‚îÄ‚îÄ‚ñ∫ X_{t+2} ‚îÄ‚îÄ‚îÄ‚ñ∫ ...           ‚îÇ
    ‚îÇ               (PGM temporal: solo el presente determina futuro) ‚îÇ
    ‚îÇ                                                                 ‚îÇ
    ‚îÇ  HMM:         L_t ‚îÄ‚îÄ‚îÄ‚ñ∫ L_{t+1} ‚îÄ‚îÄ‚îÄ‚ñ∫ L_{t+2}  (ocultos, Markov)  ‚îÇ
    ‚îÇ                ‚îÇ         ‚îÇ          ‚îÇ                           ‚îÇ
    ‚îÇ                ‚ñº         ‚ñº          ‚ñº                           ‚îÇ
    ‚îÇ               Y_t      Y_{t+1}    Y_{t+2}    (observaciones)    ‚îÇ
    ‚îÇ               (PGM con variables latentes temporales)           ‚îÇ
    ‚îÇ                                                                 ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

CAUSAL:         X ‚îÄ‚îÄ‚îÄdo‚îÄ‚îÄ‚îÄ‚ñ∫ Y    (intervenci√≥n, no solo observaci√≥n)
                       ‚ñ≤
                       ‚îÇ
                       Z (confounder a controlar)
```

---

### Dimensi√≥n 5: Mecanismo de Restricci√≥n (El "Prior")

**Pregunta clave**: *"Dado que tengo datos finitos, ¬øqu√© supuesto adicional uso para elegir entre los infinitos modelos que ajustan los datos?"*

| Mecanismo | C√≥mo restringe | Ejemplo | Situaci√≥n real |
|-----------|----------------|---------|----------------|
| **Arquitectura** | Limita qu√© funciones son representables | CNN (invarianza traslacional), Transformer (atenci√≥n) | *Reconocimiento de objetos*: un gato es gato est√© arriba o abajo de la imagen |
| **Penalizaci√≥n** | Castiga complejidad en la funci√≥n de p√©rdida | L2 = funciones suaves, L1 = funciones sparse | *Regresi√≥n con muchas variables*: L1 fuerza a usar solo las importantes |
| **Prior probabil√≠stico** | Distribuci√≥n expl√≠cita sobre par√°metros | Prior Gaussiano en pesos, GP kernel | *Pocos datos*: "creo que los par√°metros est√°n cerca de cero" |
| **Independencia condicional** | Asume que ciertas variables son independientes dadas otras | Propiedad de Markov, Naive Bayes, PGMs | *Markov*: el pasado lejano no importa dado el presente |
| **Calibraci√≥n/Momentos** | Match de momentos/estad√≠sticas observadas | SMM, GMM (Momentos Generalizados), calibraci√≥n econ√≥mica | *DSGE*: ajustar para que el modelo reproduzca volatilidad del PIB observada |
| **Validaci√≥n cruzada** | Selecci√≥n por performance en held-out | CV, train/val/test split | *Elegir hiperpar√°metros*: probar en datos que el modelo no vio |
| **Invarianza causal** | Solo usar relaciones estables bajo cambio de distribuci√≥n | IRM, Causal regularization | *Modelo m√©dico* que funcione igual en hospitales diferentes |

**Insight fundamental**: 
Todo mecanismo de restricci√≥n es matem√°ticamente equivalente a alg√∫n tipo de "prior" o creencia sobre qu√© funciones son m√°s plausibles.

| Restricci√≥n | Equivalencia Bayesiana |
|-------------|------------------------|
| L2 regularization | Prior Gaussiano sobre pesos |
| L1 regularization | Prior Laplaciano sobre pesos |
| Dropout | Prior sobre redes sparse |
| CNN architecture | Prior de invarianza traslacional |
| Propiedad de Markov | Prior de independencia condicional temporal |
| Validaci√≥n cruzada | Prior impl√≠cito de generalizaci√≥n |

---

## Parte 2: Matriz de M√©todos

Cada m√©todo concreto es un punto en el espacio 5D. Aqu√≠ est√° la ubicaci√≥n de los m√©todos m√°s comunes.

### M√©todos Supervisados (con Y)

| M√©todo | D1: Fuente | D2: Prob | D3: Objetivo | D4: Arquitectura | D5: Restricci√≥n | Caso de uso t√≠pico |
|--------|------------|----------|--------------|------------------|-----------------|-------------------|
| **Regresi√≥n Lineal** | Inductivo | Freq | **E[Y\|X]** | Flat | Ninguna/L2 | Predicci√≥n de ventas simple |
| **Ridge/Lasso** | Inductivo | Freq | **E[Y\|X]** | Flat | L2/L1 | Muchas features, pocas observaciones |
| **Logistic Regression** | Inductivo | Freq | **P(Y\|X)** | Flat | Ninguna/L2 | Clasificaci√≥n binaria interpretable |
| **Random Forest** | Inductivo | Freq | **E[Y\|X]** | Flat | Ensemble | Clasificaci√≥n tabular robusta |
| **XGBoost/LightGBM** | Inductivo | Freq | **E[Y\|X]** | Flat | Boosting+Regularizaci√≥n | Competencias, datos tabulares |
| **Deep Neural Net** | Inductivo | Freq | **E[Y\|X]** | Flat | Arquitectura+L2 | Im√°genes, texto, se√±ales |
| **Gaussian Process** | Inductivo | Bayes | **P(Y\|X)** | Flat | Kernel (prior) | Optimizaci√≥n con pocos datos |
| **Bayesian Neural Net** | Inductivo | Bayes | **P(Y\|X)** | Flat | Prior en pesos | Incertidumbre en deep learning |
| **Quantile Regression** | Inductivo | Freq | **QŒ±(Y\|X)** | Flat | Ninguna | VaR en finanzas, predicci√≥n robusta |
| **Bayesian Network** | H√≠brido | Bayes | **P(Y,X,Z)** | Grafo | Estructura expl√≠cita | Diagn√≥stico, sistemas expertos |
| **DSGE calibrado** | Deductivo | Freq | **P(Y\|X)** | Grafo | Momentos | Pol√≠tica macroecon√≥mica |
| **Bayesian DSGE** | Deductivo | Bayes | **P(Y\|X)** | Grafo | Prior+Momentos | Bancos centrales |
| **Causal Forest** | Inductivo | Freq | **P(Y\|do(X))** | Causal | Ensemble | Efectos heterog√©neos de tratamiento |
| **Double ML** | Inductivo | Freq | **P(Y\|do(X))** | Causal | Cross-fitting | Inferencia causal con ML |
| **Physics-Informed NN** | H√≠brido | Freq | **E[Y\|X]** | Flat | Ecuaciones | Simulaci√≥n con datos escasos |
| **Conformal Prediction** | Inductivo | Freq | Intervalo | Flat | Calibraci√≥n | Intervalos con garant√≠as |

### M√©todos No Supervisados (sin Y)

| M√©todo | D1: Fuente | D2: Prob | D3: Objetivo | D4: Arquitectura | D5: Restricci√≥n | Caso de uso t√≠pico |
|--------|------------|----------|--------------|------------------|-----------------|-------------------|
| **K-Means** | Inductivo | Freq | Clusters | Flat | K fijo | Segmentaci√≥n de clientes |
| **Gaussian Mixture Model** | Inductivo | Freq/Bayes | **P(X)** | Latente | Mezcla Gaussiana | Clustering probabil√≠stico |
| **PCA** | Inductivo | Freq | **œï(X)** | Latente | Linealidad | Reducci√≥n de dimensi√≥n |
| **t-SNE/UMAP** | Inductivo | Freq | **œï(X)** | Latente | Preservar vecindarios | Visualizaci√≥n |
| **Autoencoder** | Inductivo | Freq | **E[X]** (reconstrucci√≥n) | Latente | Arquitectura | Compresi√≥n, denoising |
| **VAE** | Inductivo | Bayes | **P(X)** | Latente | Prior Gaussiano | Generaci√≥n de im√°genes |
| **GAN** | Inductivo | Freq | **P(X)** impl√≠cito | Latente | Adversarial | Generaci√≥n realista |
| **Normalizing Flow** | Inductivo | Freq | **P(X)** exacto | Latente | Invertibilidad | Densidad exacta, generaci√≥n |
| **KDE** | Inductivo | Freq | **P(X)** | Flat | Kernel | Detecci√≥n de anomal√≠as simple |
| **Isolation Forest** | Inductivo | Freq | Anomal√≠a score | Flat | Ensemble | Detecci√≥n de outliers |

### M√©todos Self-Supervised

| M√©todo | D1: Fuente | D2: Prob | D3: Objetivo | D4: Arquitectura | D5: Restricci√≥n | Caso de uso t√≠pico |
|--------|------------|----------|--------------|------------------|-----------------|-------------------|
| **Word2Vec** | Inductivo | Freq | **P(ctx\|word)** | Latente | Ventana de contexto | Embeddings de palabras |
| **BERT** | Inductivo | Freq | **P(X‚Çò‚Çê‚Çõ‚Çñ\|X·µ£‚Çë‚Çõ‚Çú‚Çí)** | Latente | Transformer | Embeddings de texto |
| **GPT** | Inductivo | Freq | **P(X‚Çú‚Çä‚ÇÅ\|X‚ÇÅ:‚Çú)** | Latente | Transformer | Generaci√≥n de texto |
| **SimCLR** | Inductivo | Freq | **œï(X)** contrastivo | Latente | Augmentaciones | Representaciones visuales |
| **CLIP** | Inductivo | Freq | **œï(X) ‚âà œï(Z)** | Latente | Contrastivo multimodal | Imagen-texto alignment |
| **MAE** | Inductivo | Freq | **E[X‚Çò‚Çê‚Çõ‚Çñ\|X·µ•·µ¢‚Çõ]** | Latente | Masking+Transformer | Pretraining visual |

### M√©todos Secuenciales/Temporales (Markov)

| M√©todo | D1: Fuente | D2: Prob | D3: Objetivo | D4: Arquitectura | D5: Restricci√≥n | Caso de uso t√≠pico |
|--------|------------|----------|--------------|------------------|-----------------|-------------------|
| **Cadena de Markov** | H√≠brido | Freq | **P(X_{t+1}\|X_t)** | Grafo | Propiedad Markov | Transiciones de estados, PageRank |
| **HMM** | H√≠brido | Freq/Bayes | **P(Y\|L), P(L_{t+1}\|L_t)** | Latente+Grafo | Markov + Emisi√≥n | Reconocimiento de voz, gen√≥mica |
| **Kalman Filter** | H√≠brido | Bayes | **P(L_t\|Y_{1:t})** | Latente+Grafo | Gaussiano+Lineal | Tracking, navegaci√≥n, fusi√≥n sensores |
| **Particle Filter** | H√≠brido | Bayes | **P(L_t\|Y_{1:t})** | Latente+Grafo | Markov (no lineal) | Tracking con no-linealidades |

### IA Generativa Moderna: LLMs y Generadores de Im√°genes

Los modelos de "IA Generativa" que dominan hoy (ChatGPT, Stable Diffusion, DALL-E, Midjourney) son combinaciones espec√≠ficas en nuestra taxonom√≠a de 5 dimensiones:

| Modelo | Tipo | D1 | D2 | D3: Objetivo | D4: Arquitectura | D5: Restricci√≥n |
|--------|------|----|----|--------------|------------------|-----------------|
| **GPT-4 / LLaMA** | LLM | Inductivo | Freq | **P(X‚Çú‚Çä‚ÇÅ\|X‚ÇÅ:‚Çú)** | Latente | Transformer + Scale |
| **Claude / Gemini** | LLM | Inductivo | Freq | **P(X‚Çú‚Çä‚ÇÅ\|X‚ÇÅ:‚Çú)** | Latente | Transformer + RLHF |
| **BERT** | Encoder | Inductivo | Freq | **P(X‚Çò‚Çê‚Çõ‚Çñ\|X·µ£‚Çë‚Çõ‚Çú‚Çí)** | Latente | Transformer (bidireccional) |
| **Stable Diffusion** | Imagen | Inductivo | Freq | **P(X\|texto)** | Latente | U-Net + Diffusion |
| **DALL-E 3** | Imagen | Inductivo | Freq | **P(X\|texto)** | Latente | Transformer + Diffusion |
| **Midjourney** | Imagen | Inductivo | Freq | **P(X\|texto)** | Latente | Diffusion |
| **Sora** | Video | Inductivo | Freq | **P(X\|texto)** | Latente | Diffusion Transformer |

**Insight clave**: Todos comparten:
- **D1: Inductivo** - aprenden de datos masivos, no de teor√≠a
- **D4: Latente** - trabajan con representaciones internas comprimidas
- La diferencia est√° en **D3** (qu√© predicen) y **D5** (qu√© arquitectura/restricci√≥n usan)

**¬øC√≥mo funcionan?**

```
LLM (GPT, Claude):
    
    "El gato est√° en" ‚îÄ‚îÄ‚îÄ‚ñ∫ Transformer ‚îÄ‚îÄ‚îÄ‚ñ∫ P(siguiente palabra)
                                                  ‚îÇ
                                                  ‚ñº (muestrear)
                                             "el tejado"
    
    Autoregresivo: genera token por token, cada uno condiciona el siguiente
    Objetivo: P(X‚Çú‚Çä‚ÇÅ | X‚ÇÅ, X‚ÇÇ, ..., X‚Çú)

DIFFUSION (Stable Diffusion, DALL-E, Midjourney):
    
    Entrenamiento:
        Imagen real ‚îÄ‚îÄ‚îÄ‚ñ∫ Agregar ruido gradualmente ‚îÄ‚îÄ‚îÄ‚ñ∫ Ruido puro
                    ‚óÑ‚îÄ‚îÄ‚îÄ Aprender a QUITAR ruido ‚óÑ‚îÄ‚îÄ‚îÄ
    
    Generaci√≥n:
        Ruido puro ‚îÄ‚îÄ‚îÄ‚ñ∫ Quitar ruido paso a paso ‚îÄ‚îÄ‚îÄ‚ñ∫ Imagen generada
                              ‚ñ≤
                              ‚îÇ
        "un gato astronauta" ‚îÄ‚îò (texto condiciona el proceso)
    
    Objetivo: P(X | texto) via proceso de denoising
```

**¬øPor qu√© son "generativos"?**

| Modelo | ¬øModela P(X)? | ¬øGenera contenido nuevo? | Tipo de "generativo" |
|--------|---------------|--------------------------|----------------------|
| LLM | S√≠, P(texto) autoregressivamente | S√≠ | Generativo (capacidad + arquitectura) |
| Diffusion | S√≠, P(imagen\|texto) | S√≠ | Generativo (capacidad + arquitectura) |
| BERT | No directamente | No (es encoder) | No generativo |
| Clasificador | No, solo P(Y\|X) | No | Discriminativo |

---

## Parte 3: Gu√≠a de Decisi√≥n

### √Årbol de decisi√≥n

```mermaid
flowchart TD
    START(["üéØ PROBLEMA DE PREDICCI√ìN"]) --> Q1
    
    Q1{"<b>D1: FUENTE DE CONOCIMIENTO</b><br/>¬øDe d√≥nde viene la estructura?"}
    
    Q1 -->|"Teor√≠a completa<br/>(f√≠sica, econom√≠a)"| D1_DED["<b>DEDUCTIVO</b><br/>Ecuaciones te√≥ricas"]
    Q1 -->|"Teor√≠a + datos<br/>(calibraci√≥n)"| D1_HIB["<b>H√çBRIDO</b><br/>Estructura te√≥rica, par√°metros de datos"]
    Q1 -->|"Solo datos<br/>(ML cl√°sico)"| D1_IND["<b>INDUCTIVO</b><br/>Todo se aprende"]
    
    D1_DED --> Q2
    D1_HIB --> Q2
    D1_IND --> Q2
    
    Q2{"<b>D2: INTERPRETACI√ìN PROBABIL√çSTICA</b><br/>¬øC√≥mo tratas la incertidumbre?"}
    
    Q2 -->|"Actualizar creencias<br/>con datos"| D2_BAY["<b>BAYESIANO</b><br/><b>P(Œ∏|datos)</b>"]
    Q2 -->|"Frecuencias<br/>l√≠mite"| D2_FRQ["<b>FREQUENTIST</b><br/><b>MLE</b>, intervalos"]
    
    D2_BAY --> Q3
    D2_FRQ --> Q3
    
    Q3{"<b>D3: OBJETIVO MATEM√ÅTICO</b><br/>¬øTienes variable objetivo Y?"}
    
    Q3 -->|"S√≠, supervisado"| Q4
    Q3 -->|"No, unsupervised"| Q4B
    
    Q4{"¬øQu√© estad√≠stico de Y necesitas?"}
    
    Q4 -->|"<b>Media</b>"| D3_EY["<b>E[Y|X]</b><br/>Predicci√≥n puntual"]
    Q4 -->|"<b>Distribuci√≥n</b>"| D3_PY["<b>P(Y|X)</b><br/>Incertidumbre total"]
    Q4 -->|"<b>Percentiles</b>"| D3_Q["<b>QŒ±[Y|X]</b><br/>VaR, intervalos"]
    Q4 -->|"<b>Intervenci√≥n</b>"| D3_DO["<b>P(Y|do(X))</b><br/>Causalidad"]
    
    Q4B{"¬øQu√© quieres de X?"}
    
    Q4B -->|"<b>Densidad</b>"| D3_PX["<b>P(X)</b><br/>Anomal√≠as, generaci√≥n"]
    Q4B -->|"<b>Compresi√≥n</b>"| D3_PHI["<b>œï(X)</b><br/>Embeddings"]
    Q4B -->|"<b>Clusters</b>"| D3_C["<b>P(C|X)</b><br/>Segmentaci√≥n"]
    
    D3_EY --> Q5
    D3_PY --> Q5
    D3_Q --> Q5
    D3_DO --> D4_CAUS["<b>CAUSAL</b><br/><b>DAG</b> con <b>do()</b>"]
    D3_PX --> Q5B
    D3_PHI --> Q5B
    D3_C --> Q5B
    
    Q5{"<b>D4: ARQUITECTURA</b><br/>¬øEstructura entre variables?"}
    
    Q5 -->|"Features intercambiables"| D4_FLAT["<b>FLAT</b><br/><b>X ‚Üí f(Œ∏) ‚Üí Y</b>"]
    Q5 -->|"Dependencias expl√≠citas"| D4_GRAF["<b>PGM</b><br/><b>DAG</b>, <b>MRF</b>, <b>HMM</b>"]
    Q5 -->|"Variable oculta L"| D4_LAT["<b>LATENTE</b><br/><b>L ‚Üí X, Y</b>"]
    
    Q5B{"¬øEstructura en datos?"}
    
    Q5B -->|"Ninguna especial"| D4B_FLAT["<b>FLAT</b>"]
    Q5B -->|"Manifold/Embedding"| D4B_LAT["<b>LATENTE</b><br/><b>P(X|L)</b>, VAE"]
    Q5B -->|"Mezcla de distribuciones"| D4B_GEN["<b>GENERATIVA</b><br/><b>P(X)</b>, Gaussian Mixture"]
    
    D4_FLAT --> Q6
    D4_GRAF --> Q6
    D4_LAT --> Q6
    D4_CAUS --> Q6
    D4B_FLAT --> Q6
    D4B_LAT --> Q6
    D4B_GEN --> Q6
    
    Q6{"<b>D5: RESTRICCI√ìN</b><br/>¬øC√≥mo limitas el espacio de hip√≥tesis?"}
    
    Q6 -->|"Simetr√≠a/Invarianza"| D5_ARQ["<b>ARQUITECTURA</b><br/><b>CNN</b>, <b>Transformer</b>"]
    Q6 -->|"Penalizar complejidad"| D5_PEN["<b>REGULARIZACI√ìN</b><br/><b>L1</b>, <b>L2</b>, Dropout"]
    Q6 -->|"Creencia previa"| D5_PRI["<b>PRIOR</b><br/><b>P(Œ∏)</b>"]
    Q6 -->|"Match de momentos"| D5_CAL["<b>CALIBRACI√ìN</b><br/><b>E[g(X,Œ∏)]=0</b>"]
    Q6 -->|"Performance en holdout"| D5_CV["<b>VALIDACI√ìN</b><br/>CV, train/test"]
    Q6 -->|"Independencia temporal"| D5_MRK["<b>MARKOV</b><br/><b>P(X‚Çú‚Çä‚ÇÅ|X‚Çú)</b>"]
```

### Preguntas diagn√≥sticas r√°pidas

| Si tu situaci√≥n es... | Considera... |
|-----------------------|--------------|
| Muchos datos, sin teor√≠a previa | Inductivo + Frequentist + DNN |
| Pocos datos, conocimiento experto | H√≠brido + Bayesian + PGM |
| Necesitas tomar decisiones/pol√≠ticas | Cualquier D1 + Causal + Invarianza |
| Im√°genes/texto/se√±ales | Inductivo + Arquitectura especializada (CNN, Transformer) |
| Datos tabulares estructurados | Inductivo + Gradient Boosting |
| Cuantificar riesgo | Quantiles o Bayesian + **P(Y\|X)** |
| Detectar anomal√≠as | Inductivo + **P(X)** + Density estimation |
| Generar datos sint√©ticos | Inductivo + **P(X)** + VAE/GAN/Flow |
| Transfer learning | Self-supervised + Latente |
| Simulaci√≥n con f√≠sica conocida | H√≠brido + Physics-Informed |
| Econom√≠a/macro | Deductivo + Calibraci√≥n/Momentos |

---

## Parte 4: Casos de Estudio

### Caso 1: Econom√≠a Macroecon√≥mica (DSGE)

**Problema**: Simular efectos de pol√≠tica monetaria

| Dimensi√≥n | Elecci√≥n | Justificaci√≥n |
|-----------|----------|---------------|
| D1: Fuente | **Deductivo** | Teor√≠a econ√≥mica (Euler equations, equilibrio general) dicta la estructura |
| D2: Probabilidad | **Frequentist** (o Bayesian en bancos centrales modernos) | Calibrar a momentos observados |
| D3: Objetivo | **P(Y\|X)** | Distribuci√≥n de outcomes dado shocks |
| D4: Arquitectura | **Grafo** | Sistema de ecuaciones con dependencias expl√≠citas |
| D5: Restricci√≥n | **Momentos/Calibraci√≥n** | Ajustar para reproducir volatilidades, correlaciones observadas |

**Flujo**:
```
Teor√≠a microecon√≥mica ‚îÄ‚îÄ‚ñ∫ Ecuaciones estructurales ‚îÄ‚îÄ‚ñ∫ Par√°metros a calibrar
                                                              ‚îÇ
                                               Datos macroecon√≥micos
                                                              ‚îÇ
                                              Match de momentos (SMM)
                                                              ‚îÇ
                                              Modelo calibrado ‚îÄ‚îÄ‚ñ∫ Simulaci√≥n de pol√≠tica
```

---

### Caso 2: Computer Vision (Clasificaci√≥n de im√°genes)

**Problema**: Clasificar im√°genes en categor√≠as

| Dimensi√≥n | Elecci√≥n | Justificaci√≥n |
|-----------|----------|---------------|
| D1: Fuente | **Inductivo** | No hay "teor√≠a de im√°genes"; patrones emergen de datos |
| D2: Probabilidad | **Frequentist** | Optimizar cross-entropy loss |
| D3: Objetivo | **P(Y\|X)** via softmax | Distribuci√≥n sobre clases |
| D4: Arquitectura | **Flat** (pero CNN impone estructura) | Todas las features ‚Üí output |
| D5: Restricci√≥n | **Arquitectura (CNN)** | Invarianza traslacional: objeto es igual donde sea en la imagen |

**Por qu√© CNN**:
- Un gato en la esquina superior izquierda es el mismo gato que en el centro
- Convoluci√≥n + pooling implementan esta invarianza matem√°ticamente
- Es un "prior duro" sobre la clase de funciones

---

### Caso 3: Medicina (Decisi√≥n de tratamiento)

**Problema**: ¬øDar tratamiento A o B a un paciente?

| Dimensi√≥n | Elecci√≥n | Justificaci√≥n |
|-----------|----------|---------------|
| D1: Fuente | **H√≠brido** | Conocimiento m√©dico + datos de ensayos |
| D2: Probabilidad | **Bayesian** | Necesitas incertidumbre para decisiones de vida/muerte |
| D3: Objetivo | **P(Y\|do(X))** | ¬øQu√© pasa si DOY este tratamiento? (causal) |
| D4: Arquitectura | **Causal** | Distinguir correlaci√≥n de causaci√≥n |
| D5: Restricci√≥n | **Prior cl√≠nico** | Conocimiento m√©dico previo sobre efectos |

**Por qu√© causal**:
- Pacientes que reciben tratamiento A pueden ser diferentes de los que reciben B (confounding)
- Queremos saber qu√© pasa si INTERVENIMOS, no solo qu√© se observa
- Un modelo correlacional podr√≠a decir "A es mejor" porque pacientes m√°s sanos lo reciben

---

### Caso 4: Finanzas (Value at Risk)

**Problema**: ¬øCu√°l es la p√©rdida m√°xima del portafolio al 95%?

| Dimensi√≥n | Elecci√≥n | Justificaci√≥n |
|-----------|----------|---------------|
| D1: Fuente | **Inductivo** | Mercados son complejos, sin teor√≠a simple |
| D2: Probabilidad | **Frequentist** | Estimar quantiles emp√≠ricos |
| D3: Objetivo | **Q‚ÇÄ.‚ÇÄ‚ÇÖ(Y\|X)** | El percentil 5, no la media |
| D4: Arquitectura | **Flat** | Features de mercado ‚Üí p√©rdida |
| D5: Restricci√≥n | **Validaci√≥n** | Backtesting en datos hist√≥ricos |

**Por qu√© quantiles, no media**:
- La media de p√©rdidas es irrelevante para riesgo
- Importa el peor caso razonable (cola de la distribuci√≥n)
- **E[Y|X]** puede ser positivo mientras **Q‚ÇÄ.‚ÇÄ‚ÇÖ(Y|X)** es muy negativo

---

### Caso 5: NLP Moderno (GPT, BERT)

**Problema**: Representaciones de texto para m√∫ltiples tareas

| Dimensi√≥n | Elecci√≥n | Justificaci√≥n |
|-----------|----------|---------------|
| D1: Fuente | **Inductivo** | No hay gram√°tica formal suficiente; aprender de corpus |
| D2: Probabilidad | **Frequentist** | Maximizar likelihood |
| D3: Objetivo | **P(X‚Çú‚Çä‚ÇÅ\|X‚ÇÅ:‚Çú)** (GPT) o **P(X‚Çò‚Çê‚Çõ‚Çñ\|X·µ£‚Çë‚Çõ‚Çú‚Çí)** (BERT) | Self-supervised: Y se deriva de X |
| D4: Arquitectura | **Latente** | Aprender representaci√≥n oculta del lenguaje |
| D5: Restricci√≥n | **Arquitectura Transformer** | Atenci√≥n permite capturar dependencias largas |

**Por qu√© self-supervised**:
- Etiquetar texto para cada tarea es costos√≠simo
- El propio texto contiene "supervisi√≥n gratuita" (predecir palabras)
- Representaciones aprendidas transfieren a muchas tareas downstream

---

### Caso 6: Detecci√≥n de Fraude

**Problema**: Identificar transacciones fraudulentas

| Dimensi√≥n | Elecci√≥n | Justificaci√≥n |
|-----------|----------|---------------|
| D1: Fuente | **Inductivo** | Fraude evoluciona, no hay modelo te√≥rico estable |
| D2: Probabilidad | **Frequentist** | Estimar densidad |
| D3: Objetivo | **P(X)** | Transacciones an√≥malas = baja probabilidad |
| D4: Arquitectura | **Flat** | Features de transacci√≥n |
| D5: Restricci√≥n | **Densidad/Ensemble** | KDE, Isolation Forest |

**Por qu√© unsupervised**:
- Hay muy pocos ejemplos de fraude etiquetado
- Los fraudulentos son "diferentes" de los normales
- **P(X)** bajo = "esta transacci√≥n no se parece a las normales"

---

### Caso 7: Rob√≥tica (Fusi√≥n de sensores)

**Problema**: Estimar posici√≥n real a partir de GPS + aceler√≥metro + giroscopio

| Dimensi√≥n | Elecci√≥n | Justificaci√≥n |
|-----------|----------|---------------|
| D1: Fuente | **Inductivo** (o H√≠brido si usas modelo f√≠sico de movimiento) | Calibrar con datos |
| D2: Probabilidad | **Bayesian** | Actualizar creencia sobre posici√≥n con cada medici√≥n |
| D3: Objetivo | **P(L\|X,Z)** | Distribuci√≥n de posici√≥n latente dado sensores |
| D4: Arquitectura | **Latente** | Posici√≥n real L genera observaciones ruidosas X, Z |
| D5: Restricci√≥n | **Modelo de proceso (Kalman)** | F√≠sica del movimiento como prior |

**Por qu√© latente + Bayesian**:
- La posici√≥n real es UNA, pero la medimos con m√∫ltiples sensores ruidosos
- Cada sensor tiene diferente tipo de ruido (GPS salta, aceler√≥metro drifta)
- Kalman filter fusiona √≥ptimamente bajo supuestos Gaussianos

---

### Caso 8: F√≠sica Computacional (Simulaci√≥n de fluidos)

**Problema**: Resolver Navier-Stokes r√°pidamente

| Dimensi√≥n | Elecci√≥n | Justificaci√≥n |
|-----------|----------|---------------|
| D1: Fuente | **H√≠brido** | Ecuaciones de f√≠sica conocidas + datos para acelerar |
| D2: Probabilidad | **Frequentist** | Minimizar error de reconstrucci√≥n |
| D3: Objetivo | **E[Y\|X]** | Estado futuro del fluido dado inicial |
| D4: Arquitectura | **Flat** (con estructura de f√≠sica en loss) | Features ‚Üí estado |
| D5: Restricci√≥n | **Ecuaciones diferenciales** | Loss incluye residual de Navier-Stokes |

**Por qu√© Physics-Informed**:
- Resolver ecuaciones exactas es muy lento
- NN puede aproximar soluci√≥n r√°pidamente
- Pero sin f√≠sica, NN puede violar conservaci√≥n de masa/energ√≠a
- Agregar ecuaciones al loss = "prior de f√≠sica"

---

## El Rol de Z vs L (Variables Auxiliares y Latentes)

**Distinci√≥n fundamental:**
- **Z (observable)**: Informaci√≥n adicional que *tienes* en tus datos
- **L (latente)**: Representaci√≥n oculta que *infiere* el modelo

```
OBSERVABLE:     X ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ Y       (datos que tienes)
                    ‚îî‚îÄ‚îÄ Z

LATENTE:        X ‚îÄ‚îÄ‚îÄ‚ñ∫ L ‚îÄ‚îÄ‚îÄ‚ñ∫ XÃÇ  (L es inferido, no observado)
```

### Roles de Z (variable auxiliar observable)

| Rol de Z | Descripci√≥n | C√≥mo se usa | Ejemplo |
|----------|-------------|-------------|---------|
| **Feature adicional** | Informaci√≥n extra para predecir Y | Concatenar con X: **P(Y\|X,Z)** | Predecir ventas: X=historial, Z=clima |
| **Proxy ruidoso de X** | Z mide lo mismo que X con error | Modelos de error de medici√≥n | Encuestas: respuesta observada Z vs opini√≥n real X |
| **Vista alternativa** | X y Z son perspectivas del mismo objeto | Contrastive learning: **œï(X) ‚âà œï(Z)** | Imagen y su descripci√≥n textual (CLIP) |
| **Confounder** | Variable que afecta tanto X como Y | Controlar/bloquear en an√°lisis causal | Educaci√≥n afecta tanto ingreso como salud |
| **Instrumento** | Variable que afecta Y solo a trav√©s de X | IV regression | Distancia a universidad como instrumento para educaci√≥n |
| **Variable de agrupaci√≥n** | Define subpoblaciones | Cobertura condicional en Conformal | Garantizar precisi√≥n por g√©nero/edad |

### Roles de L (variable latente)

| Rol de L | Descripci√≥n | C√≥mo se usa | Ejemplo |
|----------|-------------|-------------|---------|
| **Representaci√≥n comprimida** | Embedding de dimensi√≥n menor | **œï(X) ‚Üí L** donde dim(L) < dim(X) | Autoencoder, PCA |
| **Estado oculto** | Variable no medida que genera observaciones | **P(X\|L)** donde L causa X | HMM: L=estado del sistema, X=mediciones |
| **Factor latente** | Causa com√∫n de m√∫ltiples observaciones | X, Z son vistas ruidosas de L | Factor Analysis: L=inteligencia, X,Z=tests |
| **Espacio generativo** | De donde se muestrean nuevos datos | **P(L)** y **P(X\|L)** | VAE: L~N(0,I), luego decodificar a imagen |

---

## Combinaciones Comunes vs Raras

### Combinaciones muy comunes (campo maduro)
- **Inductivo + Frequentist + E[Y|X] + Flat + Arquitectura** = Deep Learning est√°ndar
- **Inductivo + Bayesian + P(Y|X) + Flat + Prior** = Gaussian Processes
- **Deductivo + Frequentist + Grafo + Momentos** = Econom√≠a estructural

### Combinaciones menos comunes pero v√°lidas (campo emergente)
- **Deductivo + Bayesian + Grafo + Prior** = Bayesian DSGE (bancos centrales)
- **Inductivo + Frequentist + Causal + Invarianza** = IRM, Causal ML
- **H√≠brido + Frequentist + P(X) + Arquitectura+Ecuaciones** = Physics-informed generative models

### Combinaciones raras/inexploradas (oportunidades de investigaci√≥n)
- **Deductivo + Frequentist + œï(X) + Latente** = ¬øAutoencoders con estructura te√≥rica?
- **Deductivo + cualquier cosa + Deep Learning** = Espacio muy subexplorado
- La mayor√≠a de Deep Learning es Inductivo; hay oportunidad en Deductivo+Deep

---

## Conclusi√≥n

La predicci√≥n en IA no es un problema monol√≠tico con una soluci√≥n √∫nica. Es un espacio multidimensional donde cada m√©todo representa una combinaci√≥n de decisiones sobre:

1. **De d√≥nde viene el conocimiento** (teor√≠a vs datos)
2. **Qu√© significa probabilidad** (frecuencia vs creencia)
3. **Qu√© cantidad estimar** (media, distribuci√≥n, efecto causal, representaci√≥n)
4. **C√≥mo se relacionan las variables** (flat, estructurado, latente, causal)
5. **C√≥mo restringir el espacio de hip√≥tesis** (arquitectura, penalizaci√≥n, priors, calibraci√≥n)

No hay m√©todo universalmente mejor. La elecci√≥n √≥ptima depende de:
- Qu√© conocimiento previo tienes
- Qu√© necesitas del output
- Cu√°ntos datos tienes
- Qu√© garant√≠as necesitas
- Qu√© estructura tiene tu problema

Esta taxonom√≠a te permite **decodificar** cualquier m√©todo nuevo encontrando su posici√≥n en las 5 dimensiones, y **dise√±ar** soluciones eligiendo conscientemente en cada eje.
